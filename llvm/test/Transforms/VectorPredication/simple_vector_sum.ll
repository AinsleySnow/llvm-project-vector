; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S --passes=vector-predication -o - < %s | FileCheck %s

; ModuleID = 'custom/simple.c'
source_filename = "custom/simple.c"
target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n32:64-S128"
target triple = "riscv64-unknown-unknown"

; Input C code:
; void addVec(long N, double *C, double *A, double *B) {
;   long I;
;   for (I = 0; I < N; I++)
;     C[I] = A[I] + B[I];
; }

; Function Attrs: nofree norecurse nosync nounwind memory(argmem: readwrite) vscale_range(2,1024)
define dso_local void @addVec(i64 noundef %N, ptr nocapture noundef writeonly %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @addVec(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[B11:%.*]] = ptrtoint ptr [[B:%.*]] to i64
; CHECK-NEXT:    [[A10:%.*]] = ptrtoint ptr [[A:%.*]] to i64
; CHECK-NEXT:    [[C9:%.*]] = ptrtoint ptr [[C:%.*]] to i64
; CHECK-NEXT:    [[CMP7:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP7]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_END:%.*]]
; CHECK:       for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = xor i64 [[N]], -1
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = call i64 @llvm.umax.i64(i64 [[TMP1]], i64 10)
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ugt i64 [[TMP2]], [[TMP0]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[FOR_BODY_PREHEADER14:%.*]], label [[VECTOR_MEMCHECK:%.*]]
; CHECK:       for.body.preheader14:
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       vector.memcheck:
; CHECK-NEXT:    [[TMP4:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP5:%.*]] = shl nuw nsw i64 [[TMP4]], 3
; CHECK-NEXT:    [[TMP6:%.*]] = sub i64 [[C9]], [[A10]]
; CHECK-NEXT:    [[DIFF_CHECK:%.*]] = icmp ult i64 [[TMP6]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = shl nuw nsw i64 [[TMP4]], 3
; CHECK-NEXT:    [[TMP8:%.*]] = sub i64 [[C9]], [[B11]]
; CHECK-NEXT:    [[DIFF_CHECK12:%.*]] = icmp ult i64 [[TMP8]], [[TMP7]]
; CHECK-NEXT:    [[CONFLICT_RDX:%.*]] = or i1 [[DIFF_CHECK]], [[DIFF_CHECK12]]
; CHECK-NEXT:    br i1 [[CONFLICT_RDX]], label [[FOR_BODY_PREHEADER14]], label [[VECTOR_BODY_PREHEADER:%.*]]
; CHECK:       vector.body.preheader:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ], [ 0, [[VECTOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    [[EVL_PHI:%.*]] = phi i64 [ [[EVL_NEXT:%.*]], [[VECTOR_BODY]] ], [ [[N]], [[VECTOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    [[TMP9:%.*]] = and i64 [[EVL_PHI]], 4294967295
; CHECK-NEXT:    [[VL:%.*]] = call i64 @llvm.riscv.vsetvli.i64(i64 [[TMP9]], i64 3, i64 0)
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[VL]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds double, ptr [[A]], i64 [[INDEX]]
; CHECK-NEXT:    [[VP_LOAD:%.*]] = call <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr [[TMP11]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP10]]), !tbaa [[TBAA4:![0-9]+]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds double, ptr [[B]], i64 [[INDEX]]
; CHECK-NEXT:    [[VP_LOAD13:%.*]] = call <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr [[TMP12]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP10]]), !tbaa [[TBAA4]]
; CHECK-NEXT:    [[VP_OP:%.*]] = call <vscale x 1 x double> @llvm.vp.fadd.nxv1f64(<vscale x 1 x double> [[VP_LOAD]], <vscale x 1 x double> [[VP_LOAD13]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP10]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds double, ptr [[C]], i64 [[INDEX]]
; CHECK-NEXT:    call void @llvm.vp.store.nxv1f64.p0(<vscale x 1 x double> [[VP_OP]], ptr [[TMP13]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP10]]), !tbaa [[TBAA4]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[VL]]
; CHECK-NEXT:    [[EVL_NEXT]] = sub i64 [[N]], [[INDEX_NEXT]]
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP14]], label [[FOR_END_LOOPEXIT15:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP8:![0-9]+]]
; CHECK:       for.body:
; CHECK-NEXT:    [[I_08:%.*]] = phi i64 [ [[INC:%.*]], [[FOR_BODY]] ], [ 0, [[FOR_BODY_PREHEADER14]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds double, ptr [[A]], i64 [[I_08]]
; CHECK-NEXT:    [[TMP15:%.*]] = load double, ptr [[ARRAYIDX]], align 8, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds double, ptr [[B]], i64 [[I_08]]
; CHECK-NEXT:    [[TMP16:%.*]] = load double, ptr [[ARRAYIDX1]], align 8, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[ADD:%.*]] = fadd double [[TMP15]], [[TMP16]]
; CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds double, ptr [[C]], i64 [[I_08]]
; CHECK-NEXT:    store double [[ADD]], ptr [[ARRAYIDX2]], align 8, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[INC]] = add nuw nsw i64 [[I_08]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INC]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_END_LOOPEXIT:%.*]], label [[FOR_BODY]], !llvm.loop [[LOOP12:![0-9]+]]
; CHECK:       for.end.loopexit:
; CHECK-NEXT:    br label [[FOR_END]]
; CHECK:       for.end.loopexit15:
; CHECK-NEXT:    br label [[FOR_END]]
; CHECK:       for.end:
; CHECK-NEXT:    ret void
;
entry:
  %B11 = ptrtoint ptr %B to i64
  %A10 = ptrtoint ptr %A to i64
  %C9 = ptrtoint ptr %C to i64
  %cmp7 = icmp sgt i64 %N, 0
  br i1 %cmp7, label %for.body.preheader, label %for.end

for.body.preheader:                               ; preds = %entry
  %0 = xor i64 %N, -1
  %1 = call i64 @llvm.vscale.i64()
  %2 = call i64 @llvm.umax.i64(i64 %1, i64 10)
  %3 = icmp ugt i64 %2, %0
  br i1 %3, label %for.body.preheader14, label %vector.memcheck

for.body.preheader14:                             ; preds = %vector.memcheck, %for.body.preheader
  br label %for.body

vector.memcheck:                                  ; preds = %for.body.preheader
  %4 = call i64 @llvm.vscale.i64()
  %5 = shl nuw nsw i64 %4, 3
  %6 = sub i64 %C9, %A10
  %diff.check = icmp ult i64 %6, %5
  %7 = shl nuw nsw i64 %4, 3
  %8 = sub i64 %C9, %B11
  %diff.check12 = icmp ult i64 %8, %7
  %conflict.rdx = or i1 %diff.check, %diff.check12
  br i1 %conflict.rdx, label %for.body.preheader14, label %vector.body.preheader

vector.body.preheader:                            ; preds = %vector.memcheck
  br label %vector.body

vector.body:                                      ; preds = %vector.body.preheader, %vector.body
  %index = phi i64 [ %index.next, %vector.body ], [ 0, %vector.body.preheader ]
  %evl.phi = phi i64 [ %evl.next, %vector.body ], [ %N, %vector.body.preheader ]
  %9 = and i64 %evl.phi, 4294967295
  %vl = call i64 @llvm.riscv.vsetvli.i64(i64 %9, i64 3, i64 0)
  %10 = trunc i64 %vl to i32
  %11 = getelementptr inbounds double, ptr %A, i64 %index
  %vp.load = call <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr %11, <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 %10), !tbaa !4
  %12 = getelementptr inbounds double, ptr %B, i64 %index
  %vp.load13 = call <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr %12, <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 %10), !tbaa !4
  %13 = fadd <vscale x 1 x double> %vp.load, %vp.load13
  %14 = getelementptr inbounds double, ptr %C, i64 %index
  call void @llvm.vp.store.nxv1f64.p0(<vscale x 1 x double> %13, ptr %14, <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i64 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 %10), !tbaa !4
  %index.next = add i64 %index, %vl
  %evl.next = sub i64 %N, %index.next
  %15 = icmp eq i64 %index.next, %N
  br i1 %15, label %for.end.loopexit15, label %vector.body, !llvm.loop !8

for.body:                                         ; preds = %for.body.preheader14, %for.body
  %I.08 = phi i64 [ %inc, %for.body ], [ 0, %for.body.preheader14 ]
  %arrayidx = getelementptr inbounds double, ptr %A, i64 %I.08
  %16 = load double, ptr %arrayidx, align 8, !tbaa !4
  %arrayidx1 = getelementptr inbounds double, ptr %B, i64 %I.08
  %17 = load double, ptr %arrayidx1, align 8, !tbaa !4
  %add = fadd double %16, %17
  %arrayidx2 = getelementptr inbounds double, ptr %C, i64 %I.08
  store double %add, ptr %arrayidx2, align 8, !tbaa !4
  %inc = add nuw nsw i64 %I.08, 1
  %exitcond.not = icmp eq i64 %inc, %N
  br i1 %exitcond.not, label %for.end.loopexit, label %for.body, !llvm.loop !12

for.end.loopexit:                                 ; preds = %for.body
  br label %for.end

for.end.loopexit15:                               ; preds = %vector.body
  br label %for.end

for.end:                                          ; preds = %for.end.loopexit15, %for.end.loopexit, %entry
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare i64 @llvm.vscale.i64() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umax.i64(i64, i64) #2

; Function Attrs: nounwind memory(none)
declare i64 @llvm.riscv.vsetvli.i64(i64, i64 immarg, i64 immarg) #3

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 1 x i64> @llvm.experimental.stepvector.nxv1i64() #1

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: read)
declare <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr nocapture, <vscale x 1 x i1>, i32) #4

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: write)
declare void @llvm.vp.store.nxv1f64.p0(<vscale x 1 x double>, ptr nocapture, <vscale x 1 x i1>, i32) #5

attributes #0 = { nofree norecurse nosync nounwind memory(argmem: readwrite) vscale_range(2,1024) "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="generic-rv64" "target-features"="+64bit,+a,+c,+d,+f,+m,+relax,+v,+zve32f,+zve32x,+zve64d,+zve64f,+zve64x,+zvl128b,+zvl32b,+zvl64b,-e,-experimental-zawrs,-experimental-zca,-experimental-zcb,-experimental-zcd,-experimental-zcf,-experimental-zihintntl,-experimental-ztso,-experimental-zvfh,-h,-save-restore,-svinval,-svnapot,-svpbmt,-xtheadba,-xtheadvdot,-xventanacondops,-zba,-zbb,-zbc,-zbkb,-zbkc,-zbkx,-zbs,-zdinx,-zfh,-zfhmin,-zfinx,-zhinx,-zhinxmin,-zicbom,-zicbop,-zicboz,-zihintpause,-zk,-zkn,-zknd,-zkne,-zknh,-zkr,-zks,-zksed,-zksh,-zkt,-zmmul,-zvl1024b,-zvl16384b,-zvl2048b,-zvl256b,-zvl32768b,-zvl4096b,-zvl512b,-zvl65536b,-zvl8192b" }
attributes #1 = { nocallback nofree nosync nounwind willreturn memory(none) }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #3 = { nounwind memory(none) }
attributes #4 = { nocallback nofree nosync nounwind willreturn memory(argmem: read) }
attributes #5 = { nocallback nofree nosync nounwind willreturn memory(argmem: write) }

!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 1, !"target-abi", !"lp64d"}
!2 = !{i32 8, !"SmallDataLimit", i32 8}
!3 = !{!"clang version 17.0.0"}
!4 = !{!5, !5, i64 0}
!5 = !{!"double", !6, i64 0}
!6 = !{!"omnipotent char", !7, i64 0}
!7 = !{!"Simple C/C++ TBAA"}
!8 = distinct !{!8, !9, !10, !11}
!9 = !{!"llvm.loop.mustprogress"}
!10 = !{!"llvm.loop.isvectorized", i32 1}
!11 = !{!"llvm.loop.unroll.runtime.disable"}
!12 = distinct !{!12, !9, !10}
